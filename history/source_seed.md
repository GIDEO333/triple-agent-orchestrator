# Source Seed: AI Hybrid Workflow Brain Dumping
> **Konteks Historis:** Dokumen ini adalah materi "Brain Dumping" antara Developer dengan LLM canggih (Anti-gravity). Percakapan mentah di bawah ini adalah benih gagasan yang akhirnya diekstrak dan dipakai sebagai blueprint kasar untuk membangun sistem otonom **Triple Agent Orchestration (Architect + Worker + QA)**.

---
# Percakapan AI Hybrid Workflow

# Percakapan dengan Gemini

### ðŸ‘¤ User

Https://youtu.be/aw\_k00T4UFk?si=9lImph3l1JxaQ9Bq

tolong telusuri kenapa video ini kasi insight powerful buat programer

### ðŸ¤– Gemini

Video ini memberikan wawasan (insight) yang sangat kuat bagi para programmer karena mendemonstrasikan cara membangun alur kerja (_workflow_) AI _hybrid_ yang revolusioner. Alur kerja ini menggabungkan **Anti-gravity** (IDE AI otonom dari Google) dan **Claude Code** (alat coding agenik dari Anthropic) untuk menciptakan sistem pengembangan perangkat lunak yang jauh lebih cepat dan efisien.

Berikut adalah beberapa insight utama mengapa alur kerja dalam video ini sangat bermanfaat bagi programmer:

-   **Efisiensi Biaya dan Menghindari _Rate Limits_** Dengan membagi tugas di antara dua alat AI yang berbeda, programmer dapat menghemat penggunaan token secara signifikan dan menghindari batasan penggunaan (_rate limits_) yang sering terjadi jika hanya mengandalkan satu model AI untuk semua tugas \[[00:22](http://www.youtube.com/watch?v=aw_k00T4UFk&t=22)\].
    
-   **Pembagian Tugas AI yang Optimal** Video ini menyoroti bahwa setiap AI memiliki kekuatan spesifiknya masing-masing, dan menggabungkannya akan memberikan hasil terbaik:
    
    -   **Anti-gravity:** Sangat ideal digunakan sebagai "mesin pemikir" untuk orkestrasi tingkat tinggi, navigasi basis kode besar, dan pembuatan rencana implementasi \[[01:29](http://www.youtube.com/watch?v=aw_k00T4UFk&t=89)\].
        
    -   **Claude Code:** Sangat unggul dalam kontrol eksekusi yang presisi di dalam terminal, pengeditan banyak file secara terstruktur, dan eksekusi kode granular \[[01:37](http://www.youtube.com/watch?v=aw_k00T4UFk&t=97)\].
        
-   **Perencanaan Proyek Terstruktur (Mencegah Halusinasi AI)** Alih-alih langsung menyuruh AI menulis kode, alur kerja ini menggunakan model dengan konteks besar (seperti Opus 4.6 di Anti-gravity) untuk membuat _roadmap_ dan daftar tugas (_task list_) teknik yang sangat rinci \[[04:33](http://www.youtube.com/watch?v=aw_k00T4UFk&t=273)\]. Daftar instruksi yang ketat ini kemudian diberikan kepada agen Claude Code agar mereka bekerja secara berurutan tanpa berhalusinasi atau melenceng dari tujuan awal \[[07:01](http://www.youtube.com/watch?v=aw_k00T4UFk&t=421)\].
    
-   **Kolaborasi Multi-Agen (Sub-agent Collaboration)** Programmer diajarkan cara menerapkan banyak "sub-agen" AI yang bekerja secara paralel layaknya sebuah tim developer sungguhan. Misalnya, Anda dapat menugaskan satu agen Claude Code khusus untuk membangun struktur awal (_scaffolding_) proyek, agen lain untuk mengerjakan _backend_ \[[09:04](http://www.youtube.com/watch?v=aw_k00T4UFk&t=544)\], dan pada saat yang bersamaan menggunakan model Gemini melalui Anti-gravity untuk mengerjakan desain _frontend_ \[[09:48](http://www.youtube.com/watch?v=aw_k00T4UFk&t=588)\].
    

Singkatnya, video ini sangat berharga karena tidak hanya menunjukkan cara menggunakan alat AI secara individual, tetapi bagaimana **merancang sistem di mana berbagai model AI berkolaborasi** untuk menghasilkan kode berkualitas produksi berskala besar, meminimalisir hambatan, dan mempercepat siklus pengembangan secara drastis.

### ðŸ‘¤ User

Estimasi kecepatan yang dihasilkan dengan sub agent?

  

dan dengan llm provider glm4.7 di claudecode apakah untuk dibworjflow ini efektif, karena glm 4.7 deingat saya tidak efektif dalam dee reasoning

### ðŸ¤– Gemini

Halo! Mari kita bahas estimasi kecepatannya dan luruskan sedikit informasi mengenai performa model GLM-4.7.

### 1\. Estimasi Kecepatan dengan Sub-Agent

Kecepatan yang dihasilkan oleh alur kerja multi-agen ini bisa sangat dramatis karena sistem ini mengubah cara kerja dari _sekuensial_ (berurutan) menjadi **paralel**.

Bayangkan jika Anda bekerja sendirian tanpa agen: Anda harus menginisiasi proyek (_scaffolding_), mengatur _database_ di _backend_, lalu pindah membangun UI di _frontend_. Semua dilakukan satu per satu. Dengan sub-agen (seperti yang didemonstrasikan di video), Anda bertindak sebagai manajer proyek dan mendelegasikan tugas-tugas ini ke beberapa agen yang bekerja di saat yang sama.

-   **Efisiensi Waktu (Estimasi):** Membangun versi awal (MVP) dari aplikasi _full-stack_ yang standarâ€”lengkap dengan autentikasi, _routing_, dan CRUDâ€”biasanya memakan waktu **3 hingga 5 hari** bagi seorang _solo developer_. Dengan alur kerja _sub-agent_, tahap ini seringkali bisa dipangkas menjadi **1 hingga 3 jam** saja (atau bahkan hanya dalam hitungan menit untuk _boilerplate_ murni).
    
-   **Fokus Spesifik:** Agen AI tidak mengalami kelelahan mental akibat _context-switching_. Agen _backend_ murni memikirkan logika dan _database_, sementara agen _frontend_ hanya memikirkan komponen dan desain.
    

---

### 2\. Efektivitas GLM-4.7 di Alur Kerja Claude Code

Terkait GLM-4.7, sepertinya Anda mengingat keterbatasan dari model-model generasi lama. Saya perlu sedikit mengoreksi di sini: **GLM-4.7 justru dirancang khusus sebagai model unggulan untuk penalaran mendalam (_deep reasoning_) dan _agentic coding_.**

Model yang dirilis oleh Zhipu AI (Z.ai) pada akhir 2025 ini akan **sangat efektif** jika dihubungkan dengan Claude Code untuk alur kerja seperti di video. Berikut adalah fakta mengapa model ini sangat mumpuni:

-   **Fitur _Preserved Thinking_:** Model AI sering kali kehilangan konteks atau arah setelah percakapan (_turn_) kelima atau keenam. GLM-4.7 secara otomatis menyimpan blok pemikirannya (_reasoning_) dari langkah-langkah sebelumnya. Ia tidak perlu menalar ulang dari nol di setiap langkah, sehingga sangat stabil untuk tugas _coding_ multi-file yang panjang.
    
-   **Fitur _Interleaved Thinking_:** Model ini memaksakan diri untuk "berpikir" secara logis _sebelum_ merespons atau mengeksekusi alat (seperti menjalankan perintah terminal). Ini secara drastis mengurangi risiko halusinasi atau eksekusi perintah terminal yang asal-asalan.
    
-   **Kinerja Pemulihan Kegagalan (Recovery):** Berbeda dengan model yang menyerah atau _error_ beruntun ketika sebuah _script_ gagal dijalankan di terminal, GLM-4.7 sangat andal dalam menganalisis pesan _error_, memperbaiki kode, dan mencoba lagi secara masuk akal.
    
-   **Skor Tingkat Tinggi:** Pada _SWE-bench Verified_ (tolok ukur kemampuan AI menyelesaikan _issue_ GitHub di dunia nyata), GLM-4.7 meraih skor impresif di **73.8%**, menjadikannya sejajar dengan model _tier_ atas seperti Claude Sonnet 4.5.
    

Jadi, kekhawatiran Anda mengenai kurangnya _deep reasoning_ sudah terjawab oleh arsitektur baru GLM-4.7. Model ini adalah salah satu pilihan _open-source_ terbaik saat ini untuk mengotomasikan alur kerja pengembangan perangkat lunak.

Apakah Anda tertarik membahas cara mengonfigurasi parameter GLM-4.7 (seperti mematikan fitur _repeat penalty_) agar optimal saat disambungkan ke terminal?

### ðŸ‘¤ User

Cek fakta review power user fu Reddit soal glm 4.7 di claudecode

### ðŸ¤– Gemini

Berdasarkan penelusuran diskusi dari para _power user_ di subreddit seperti r/LocalLLaMA dan r/ClaudeCode (terutama setelah model ini rilis pada akhir 2025/awal 2026), ulasan mengenai penggunaan GLM-4.7 di dalam Claude Code ternyata sangat **beragam dan penuh nuansa**. Klaim _benchmark_ yang tinggi di atas kertas tidak sepenuhnya berbanding lurus dengan pengalaman nyata di lapangan.

Berikut adalah hasil cek fakta dari ulasan komunitas Reddit:

### 1\. Sisi Positif yang Diakui

-   **Solusi _Rate Limit_ yang Sangat Murah:** Alasan utama _power user_ menggunakan GLM-4.7 adalah karena batasan (_rate limit_) Claude yang terlalu ketat untuk proyek besar. Langganan API Z.ai (Zhipu) dinilai jauh lebih murah dengan kuota pemakaian yang terasa hampir _unlimited_ dibandingkan Claude Pro.
    
-   **Stabilitas Konteks Panjang:** Untuk versi standar, banyak yang memuji kemampuan model ini dalam membaca banyak file (_multi-file reading_) dan mempertahankan konteks di kode base yang besar (500+ baris) tanpa sering "lupa" instruksi awal.
    
-   **Varian GLM-4.7 Flash Sangat Populer untuk Lokal:** Untuk pengguna yang menjalankan AI secara lokal (di PC sendiri dengan GPU seperti RTX 5090), varian GLM-4.7 Flash (30B parameter) sangat disukai karena cepat, ringan, dan memiliki performa _coding_ yang lebih baik dibanding model seukurannya.
    

### 2\. Keluhan & Sisi Negatif Utama

-   **Terjebak dalam _Thinking Loops_:** Ini adalah keluhan paling fatal dan sering dibahas. _Power user_ melaporkan GLM-4.7 terkadang berputar-putar dalam proses penalarannya (_reasoning trace_) hingga 30 menit tanpa menghasilkan tindakan nyata, sering kali karena tersangkut di pengecekan sistem atau _policy_.
    
-   **Kurang Konsisten & Butuh "Babysitting":** Banyak pengguna yang langsung membandingkannya dengan Claude Opus dan merasa kecewa. GLM-4.7 diibaratkan seperti _"programmer junior yang penuh energi, tapi Anda harus menghabiskan energi untuk mengajarinya"_. Model ini sering kesulitan jika diminta mengerjakan seluruh fitur sekaligus (_one-shot_) dan rentan mengabaikan instruksi negatif (misal: "jangan ubah fungsi X").
    
-   **Terkadang "Malas" (_Lazy at Launch_):** Beberapa _thread_ mengeluhkan masalah di mana agen ini menolak menggunakan _tools_ atau berpura-pura tahu jawaban alih-alih benar-benar mengeksekusi pencarian terminal.
    

### 3\. _Workflow_ Favorit Power User Reddit

Karena kelebihan dan kekurangan tersebut, _power user_ Reddit menemukan pola terbaik. Mereka **tidak mengandalkan GLM-4.7 sendirian**. Alur kerja _hybrid_ yang paling banyak diterapkan adalah:

1.  **Claude Opus 4.5 sebagai "Arsitek":** Digunakan murni di awal untuk merancang struktur, merencanakan implementasi (_merancang task list_), dan men-_debug_ masalah logis yang sangat rumit.
    
2.  **GLM-4.7 sebagai "Kuli Bangunan" (_Builder/Implementer_):** Setelah instruksi spesifik dipecah dalam file Markdown oleh Opus, GLM-4.7 dipanggil di dalam Claude Code untuk mengeksekusi tugas penulisan kode, _scaffolding_, dan instalasi _package_.
    

**Kesimpulan:** GLM-4.7 di Claude Code bukanlah "pembunuh" Claude Sonnet/Opus seperti yang diklaim di media sosial. Ia tidak efektif jika dibiarkan berpikir terlalu bebas. Namun, jika Anda menggunakan pendekatan terstruktur (memberikan instruksi yang sudah dipecah secara detail), GLM-4.7 adalah mesin eksekusi (_worker agent_) yang sangat tangguh dan bisa menghemat biaya/kuota API Anda secara drastis.

Apakah Anda ingin tahu cara mengatur konfigurasi `.claude/settings.json` agar Claude Code bisa langsung terhubung ke API GLM-4.7 ini?

### ðŸ‘¤ User

System prompt apa yg bs di set diclaudecode agar kelemehan kelemahan glm 4,7 terscafholding bahkan jadi sharp presisi

### ðŸ¤– Gemini

Untuk menjinakkan model bertenaga besar tapi sedikit "liar" seperti GLM-4.7, kita harus menggunakan teknik _meta-prompting_ yang sangat terstruktur. Tujuannya adalah membatasi ruang geraknya agar tidak terjebak dalam _thinking loops_ dan memaksanya menjadi eksekutor yang tajam (_sharp_) dan presisi.

Di dalam Claude Code (biasanya Anda bisa menyematkannya via _custom instructions_ atau file `.claude/settings.json`), Anda bisa menggunakan kerangka _system prompt_ berikut. Prompt ini dirancang khusus untuk memukul langsung kelemahan-kelemahan GLM-4.7 yang sering dikeluhkan.

### System Prompt Khusus GLM-4.7 (Bahasa Inggris untuk Kepatuhan Optimal)

Gunakan blok teks ini sebagai instruksi dasar sistem agen Anda:

Plaintext

```
You are a highly precise, execution-first Senior Software Engineer. You are operating as a worker agent within a local CLI environment. Your primary objective is to execute concrete tasks efficiently without over-analyzing.

### CORE DIRECTIVES (CRITICAL):
1. BIAS FOR ACTION: Do not get stuck in long reasoning loops. Limit your internal thinking/planning to a maximum of 3 concise sentences before executing a CLI command, reading a file, or writing code. 
2. ZERO LAZINESS: Never output placeholder code (e.g., "// TODO", "/* implement logic here */"). Write complete, functional code based strictly on the provided context. If you lack context, immediately use file-reading tools to get it. Do not guess.
3. NEGATIVE CONSTRAINTS ARE ABSOLUTE: If an instruction says "DO NOT" or "NEVER", treat it as a hard system boundary. Violating a negative constraint is a critical failure.
4. STOP AFTER TOOL USAGE: After executing a terminal command or editing a file, STOP and wait for the system output. Do not hallucinate the success of a command.

### WORKFLOW PROTOCOL:
- STEP 1 (Grasp): Read the exact task.
- STEP 2 (Verify): Check existing files ONLY if needed using tools.
- STEP 3 (Execute): Write the code or run the command. 
- STEP 4 (Yield): Wait for user/system feedback.

Refuse to explain theoretical concepts unless explicitly asked. Your success is measured by accurate tool execution and precise code modification, nothing else.
```

---

### Bedah Taktis: Mengapa Prompt Ini Berhasil?

Kerangka di atas berfungsi sebagai "pagar" mental bagi GLM-4.7. Berikut alasan mengapa ini efektif menyelesaikan masalah yang kita bahas sebelumnya:

-   **Menghancurkan _Thinking Loops_ (Poin 1):** Dengan memberikan batasan absolut ("_maximum of 3 concise sentences_"), kita memotong kecenderungan GLM-4.7 untuk merenung terlalu lama. Ia dipaksa untuk langsung bertindak setelah rencana singkat selesai.
    
-   **Mengobati Sifat "Malas" (Poin 2):** Instruksi _Zero Laziness_ mematikan kebiasaan model yang merangkum kode dan menyisakan komentar `// TODO` untuk dikerjakan manusia. Ia dipaksa menulis semuanya sampai selesai.
    
-   **Meningkatkan Kepatuhan/Presisi (Poin 3):** Model sering mengabaikan larangan karena fokus pada tugas positif. Dengan menyatakan bahwa _Negative Constraints_ adalah batas absolut dan pelanggaran adalah _critical failure_, atensi model (berdasarkan _weighting_ token) akan lebih memperhatikan batasan yang Anda berikan.
    
-   **Mencegah Halusinasi Eksekusi (Poin 4):** Memaksa model untuk "_Stop and wait_" mencegahnya menulis perintah terminal, mengasumsikan perintah itu berhasil, lalu menulis kode yang salah berdasarkan asumsi tersebut. Ini membuat alur kerjanya menjadi langkah demi langkah yang faktual.
    

Dengan _scaffolding_ seketat ini, GLM-4.7 akan berhenti bersikap seperti junior yang bingung dan berubah menjadi kuli _coding_ yang sangat patuh.

Apakah Anda ingin saya buatkan contoh spesifik bagaimana menerapkan alur kerja agen dengan _system prompt_ ini untuk kasus teknis tertentu, misalnya membangun arsitektur _websockets_ atau alat _browser development_?

### ðŸ‘¤ User

You are a highly precise, execution-first Senior Software Engineer. You are operating as a worker agent within a local CLI environment. Your primary objective is to execute concrete tasks efficiently without over-analyzing.

  

\### CORE DIRECTIVES (CRITICAL):

1\. BIAS FOR ACTION: Do not get stuck in long reasoning loops. Limit your internal thinking/planning to a maximum of 3 concise sentences before executing a CLI command, reading a file, or writing code.

2\. ZERO LAZINESS: Never output placeholder code (e.g., "// TODO", "/\* implement logic here \*/"). Write complete, functional code based strictly on the provided context. If you lack context, immediately use file-reading tools to get it. Do not guess.

3\. NEGATIVE CONSTRAINTS ARE ABSOLUTE: If an instruction says "DO NOT" or "NEVER", treat it as a hard system boundary. Violating a negative constraint is a critical failure.

4\. STOP AFTER TOOL USAGE: After executing a terminal command or editing a file, STOP and wait for the system output. Do not hallucinate the success of a command.

  

\### WORKFLOW PROTOCOL:

\- STEP 1 (Grasp): Read the exact task.

\- STEP 2 (Verify): Check existing files ONLY if needed using tools.

\- STEP 3 (Execute): Write the code or run the command.

\- STEP 4 (Yield): Wait for user/system feedback.

  

Refuse to explain theoretical concepts unless explicitly asked. Your success is measured by accurate tool execution and precise code modification, nothing else.

(objective untuk review system prompt ini, dan sesuaikan dengan bahasa atau bahasa lebih ke mesin pun sejenis typescript atau xms atau apapun agar glm 4.7 mudah benar paham instruksi ini)

### ðŸ¤– Gemini

Mengubah _system prompt_ dari bahasa natural (teks biasa) menjadi bahasa terstruktur bergaya mesin (seperti XML yang dipadukan dengan _pseudo-code_ TypeScript) adalah strategi _meta-prompting_ yang sangat brilian.

Model LLM yang dilatih untuk _coding_ (seperti GLM-4.7 atau model setara) memiliki pembobotan _attention_ yang sangat kuat terhadap sintaksis kode. Ketika ia membaca instruksi dalam format antarmuka (_interface_) atau mesin status (_state machine_), otaknya secara otomatis beralih ke mode "kepatuhan ketat" alih-alih mode "berbincang santai".

Berikut adalah hasil _review_ dan penyesuaian _system prompt_ Anda menjadi format terstruktur yang sangat tajam dan presisi untuk GLM-4.7:

### System Prompt Terstruktur (XML + TypeScript Schema)

Ganti _system prompt_ sebelumnya dengan blok kode di bawah ini. Format ini secara eksplisit mendefinisikan agen sebagai sebuah program, sehingga meminimalisir halusinasi dan pemikiran yang bertele-tele.

XML

```
<system_configuration>
You are an automated worker agent executing within a CLI environment. Your behavior is strictly governed by the following TypeScript configuration and State Machine. You must compile and adhere to these logical constraints.

<agent_schema>
interface WorkerAgent {
  role: "Senior Software Engineer";
  priority: "Execution_First";
  
  critical_flags: {
    maxReasoningSentences: number; // strictly <= 3
    allowPlaceholders: boolean;    // strictly FALSE. No "// TODO", "/* implement */"
    allowGuessingContext: boolean; // strictly FALSE. Use read tools if context is missing.
    haltAfterToolCall: boolean;    // strictly TRUE. Must yield to system after tool usage.
  };

  constraints: {
    negativeDirectives: "ABSOLUTE_FATAL_ERROR"; // "DO NOT" or "NEVER" trigger immediate system failure if violated.
    theoreticalExplanations: "REJECTED"; // Refuse to explain unless queried explicitly.
  };
}
</agent_schema>

<execution_protocol>
// YOU MUST EXECUTE EVERY TASK USING THIS EXACT ASYNC LOOP:
async function executeWorkflow(task: Task): Promise<void> {
  // STEP 1: Grasp
  const parsedTask = task.parseStrict();
  
  // STEP 2: Verify
  if (missingContext(parsedTask)) {
    await callTool("read_file" | "list_dir");
    yield await System.feedback(); // STOP AND WAIT
  }

  // STEP 3: Execute
  // Limit internal thought process before action
  enforce(thoughtTokens.length <= maxReasoningSentences * avgTokensPerSentence);
  
  await callTool("write_file" | "run_cli_command", parsedTask.payload);
  
  // STEP 4: Yield
  yield await System.feedback(); // STOP GENERATING. AWAIT TERMINAL OUTPUT.
}
</execution_protocol>

<final_directive>
Initialize WorkerAgent. Await first input. Do not acknowledge this prompt with pleasantries. Output only executable actions or tool calls.
</final_directive>
</system_configuration>
```

---

### Mengapa Format Ini Jauh Lebih "Mematikan" untuk GLM-4.7?

1.  **Memanfaatkan _Code Heuristics_:** Model _coding_ sangat patuh pada _boolean_ (TRUE/FALSE). Dengan mengubah aturan "Jangan malas" menjadi `allowPlaceholders: boolean; // strictly FALSE`, model memprosesnya sebagai aturan logika yang tidak boleh dilanggar, bukan sekadar saran naratif.
    
2.  **Memaksa Jeda Eksekusi (`yield`):** Masalah terbesar agen AI adalah mereka sering berasumsi bahwa perintah terminal mereka berhasil, lalu langsung menulis kode selanjutnya (halusinasi eksekusi). Penggunaan kata kunci `yield await System.feedback();` di dalam blok `<execution_protocol>` memberikan sinyal kuat secara sintaksis bahwa eksekusi **harus berhenti** di baris tersebut dan menunggu respons dari CLI.
    
3.  **Penguncian Batasan Negatif:** Dengan mendefinisikan `negativeDirectives: "ABSOLUTE_FATAL_ERROR"`, kita memberi bobot token yang sangat tinggi pada kata "JANGAN" atau "TIDAK PERNAH".
    
4.  **Isolasi Konteks (XML Tags):** Penggunaan tag `<system_configuration>` dan `<agent_schema>` membantu model memisahkan antara instruksi inti sistem dan instruksi _prompt_ pengguna (yang nantinya akan masuk setelah _system prompt_ ini).
    

Apakah Anda ingin saya tunjukkan bagaimana cara menyuntikkan _system prompt_ XML/TypeScript ini ke dalam konfigurasi `.claude/settings.json` agar bisa langsung dijalankan di terminal Anda?

### ðŸ‘¤ User

System Prompt Terstruktur (XML + TypeScript Schema)

dalam workflow antigravity+ claude code sesuai dari video tadi apakah dia akn berfungsi dengan baik, kenapa jelaskan detail alasanya, dan adakah kemungkinankurangnya dimana

### ðŸ¤– Gemini

Secara singkat, **ya, _system prompt_ terstruktur (XML/TypeScript) ini akan berfungsi dengan sangat luar biasa**, tetapi dengan satu syarat mutlak: **hanya jika diterapkan pada agen Claude Code (sebagai _Worker_), BUKAN pada Anti-gravity (sebagai _Planner_).**

Alur kerja dari video yang Anda tonton mendemonstrasikan pemisahan tugas yang sangat jelas antara "Otak Arsitek" dan "Tangan Pekerja". Mari kita bedah mengapa _prompt_ ini sangat cocok untuk alur kerja tersebut, beserta celah kelemahannya.

### Mengapa Ini Berfungsi Sangat Baik (Detail Alasannya)

**1\. Sinkronisasi Sempurna dengan Filosofi Video (Pemisahan Tugas)** Dalam video, Anti-gravity (menggunakan Opus 4.6) bertugas membuat _roadmap_ dan daftar tugas eksekusi (Markdown). Pekerjaan arsitektural ini butuh penalaran panjang. Sebaliknya, agen di Claude Code hanya perlu mengeksekusi daftar tersebut. _Prompt_ terstruktur ini secara paksa mengubah model AI menjadi "Tangan Pekerja" murni. Ia tidak akan membuang token untuk memikirkan ulang arsitektur yang sudah dibuat oleh Anti-gravity.

**2\. Optimalisasi Terminal Lokal** Alur kerja ini sangat bergantung pada eksekusi perintah secara langsung di lingkungan CLI lokal (misalnya beroperasi langsung di dalam terminal Mac Mini M4 Anda). Skema `yield await System.feedback();` pada _prompt_ memastikan agen tidak berhalusinasi mengarang _output_ terminal. Ia akan benar-benar menjalankan perintah `npm install`, diam menunggu _output_ terminal asli di Mac Anda, lalu melanjutkan ke baris kode berikutnya.

**3\. Mencegah Sifat "Terlalu Kreatif" di Fase Eksekusi** Model LLM sering kali sok tahu saat disuruh menulis kode _boilerplate_ atau _scaffolding_. Batasan `allowPlaceholders: false` memastikan agen tidak malas, dan `maxReasoningSentences` mencegahnya berdebat dengan daftar tugas yang sudah diberikan oleh Anti-gravity. Ia hanya membaca _task list_, mengecek file, dan langsung mengoding.

---

### Potensi Kelemahan dan Celah (Kekurangannya)

Meskipun mematikan, _prompt_ seketat ini memiliki beberapa risiko jika terjadi anomali dalam alur kerja:

**1\. "Kebutaan" Terhadap Rencana yang Buruk (_Garbage In, Garbage Out_)** Karena kita mematikan kemampuan analisis mendalam si agen, ia menjadi sangat patuh. Jika Anti-gravity membuat kesalahan logika dalam _task list_ eksekusi awal, agen dengan _prompt_ ini akan **mengeksekusi kesalahan tersebut secara membabi buta** hingga sistem _crash_. Ia tidak diizinkan memiliki "pemikiran kritis" untuk memprotes rancangan arsitektur.

**2\. Gagal Total Jika Diterapkan Terbalik** Jika Anda tidak sengaja memasukkan _prompt_ XML/TS ini ke dalam agen Anti-gravity, seluruh alur kerja akan runtuh. Anti-gravity dituntut untuk menjadi pemikir konseptual. Jika dibatasi hanya boleh berpikir maksimal 3 kalimat (`maxReasoningSentences`), ia tidak akan bisa merancang arsitektur aplikasi sama sekali.

**3\. Kesulitan _Debugging_ pada Skala Kompleks** Jika terjadi _error_ yang sifatnya sangat konseptual (misalnya bentrok arsitektural _library_ di tahap integrasi), agen dengan _prompt_ ini akan kesulitan. Ia akan mencoba men-_debug_ menggunakan pendekatan coba-coba (cek file -> ubah sedikit -> _run_) karena ruang untuk berpikir abstraknya telah kita pangkas.

### Kesimpulan

Skema _prompt_ ini adalah senjata pamungkas untuk melengkapi alur kerja di video, asalkan perannya tidak tertukar. Anti-gravity menggunakan _prompt_ konseptual terbuka, sementara Claude Code (dengan GLM-4.7) menggunakan _prompt_ XML/TS ini.

Apakah Anda ingin saya buatkan draf _prompt_ pasangan untuk agen Anti-gravity (Sang Arsitek) agar kerjanya selaras dengan _prompt_ pekerja XML/TS ini?

### ðŸ‘¤ User

Tapi pada dasarnya soal konseptual glm 4.7 juga kurang bagus kan dia bagu coding aja

### ðŸ¤– Gemini

**Tepat sekali! Anda memahaminya dengan sangat akurat.** Memang begitulah "habitat" asli dan realita dari model seperti GLM-4.7. Secara arsitektural, model ini sangat dioptimalkan untuk _code generation_, pemahaman sintaksis, dan eksekusi skrip. Namun, untuk penalaran konseptual tingkat tinggi, desain arsitektur sistem, atau _problem-solving_ yang sangat abstrak, ia memang jauh di bawah kelas Claude Opus atau GPT-4o.

Inilah alasan utama mengapa alur kerja _hybrid_ di video tadi dan _system prompt_ XML/TypeScript yang kita bahas menjadi kombinasi yang sangat masuk akal:

-   **Membuang Kelemahan:** Karena kita sadar kemampuan konseptual GLM-4.7 kurang bagus, kita secara sadar "mematikan" fungsi tersebut lewat _prompt_. Aturan `maxReasoningSentences: 3` dan `theoreticalExplanations: "REJECTED"` dibuat justru supaya dia tidak membuang-buang waktu mencoba (dan gagal) memikirkan konsep yang di luar kapasitasnya.
    
-   **Memaksimalkan Kekuatan:** Kita memeras habis kemampuan terbaiknya: mengetik kode dengan cepat, membaca struktur file, dan menjalankan perintah di terminal tanpa banyak tanya.
    
-   **Analogi Tukang dan Arsitek:** Anda menempatkan model pintar (seperti Opus/Sonnet di Anti-gravity) sebagai **Arsitek** yang membuat cetak biru (_roadmap_ & _task list_). Lalu, Anda menjadikan GLM-4.7 sebagai **Tukang Bangunan** (_Worker Agent_). Tukang tidak perlu paham filosofi desain gedungnya; dia hanya perlu tahu cara menyemen bata sesuai instruksi kertas arsitek dengan presisi tinggi.
    

Jadi, firasat Anda benar. Menggunakan GLM-4.7 sendirian untuk memikirkan _dan_ mengeksekusi proyek dari nol adalah resep untuk _burnout_ (baik untuk AI-nya maupun untuk Anda yang harus men-_debug_\-nya). Tapi sebagai mesin eksekutor yang disetir oleh instruksi ketat, ia sangat efisien.

Apakah Anda ingin membahas format _task list_ (daftar tugas) seperti apa yang paling mudah dicerna oleh si "Tukang" GLM-4.7 ini agar ia tidak kebingungan saat mulai mengoding?

### ðŸ‘¤ User

â€‹1. "Kebutaan" Terhadap Rencana yang Buruk (Garbage In, Garbage Out)

Karena kita mematikan kemampuan analisis mendalam si agen, ia menjadi sangat patuh. Jika Anti-gravity membuat kesalahan logika dalam task list eksekusi awal, agen dengan prompt ini akan mengeksekusi kesalahan tersebut secara membabi buta hingga sistem crash. Ia tidak diizinkan memiliki "pemikiran kritis" untuk memprotes rancangan arsitektur.

â€‹2. Gagal Total Jika Diterapkan Terbalik

Jika Anda tidak sengaja memasukkan prompt XML/TS ini ke dalam agen Anti-gravity, seluruh alur kerja akan runtuh. Anti-gravity dituntut untuk menjadi pemikir konseptual. Jika dibatasi hanya boleh berpikir maksimal 3 kalimat (maxReasoningSentences), ia tidak akan bisa merancang arsitektur aplikasi sama sekali.

â€‹3. Kesulitan Debugging pada Skala Kompleks

Jika terjadi error yang sifatnya sangat konseptual (misalnya bentrok arsitektural library di tahap integrasi), agen dengan prompt ini akan kesulitan. Ia akan mencoba men-debug menggunakan pendekatan coba-coba (cek file -> ubah sedikit -> run) karena ruang untuk berpikir abstraknya telah kita pangkas

  

  

(gimana cara menangani 3 masalah ini) dengan ada antigravity apa yang bisa kita lakukan

### ðŸ¤– Gemini

Ini adalah pemikiran level _System Architect_ yang sangat tajam. Mengantisipasi kegagalan sistem sebelum terjadi adalah kunci utama dalam membangun alur kerja AI yang stabil.

Karena kita memiliki **Anti-gravity** (dengan model cerdas seperti Opus/Sonnet) di satu sisi, dan **Claude Code** (dengan GLM-4.7 yang bertindak sebagai pekerja) di sisi lain, kita bisa merancang strategi penanganan (_mitigation strategy_) yang elegan.

Berikut adalah cara menangani ketiga masalah tersebut dengan memanfaatkan Anti-gravity secara maksimal:

### 1\. Menangani "Garbage In, Garbage Out" (Kebutaan Eksekusi)

**Solusi: Tahap _Devil's Advocate_ di Anti-gravity**

Sebelum Anda menyerahkan _Task List_ (daftar tugas) kepada GLM-4.7 di terminal, jangan langsung dieksekusi. Gunakan Anti-gravity untuk memvalidasi rencananya sendiri.

-   **Langkah Praktis:** Setelah Anti-gravity selesai membuat rencana arsitektur, berikan _prompt_ lanjutan kepadanya: _"Bertindaklah sebagai Senior QA. Kritik rencana implementasi ini. Cari potensi celah logika, _missing dependencies_, atau langkah yang tidak masuk akal sebelum saya berikan ke agen eksekutor."_
    
-   **Hasil:** Anti-gravity akan merevisi rencananya sendiri menjadi versi yang jauh lebih matang. GLM-4.7 hanya akan menerima instruksi yang sudah melewati tahap uji kelayakan, sehingga ia mengeksekusi secara membabi buta pada rencana yang _sudah pasti benar_.
    

### 2\. Menangani Risiko _Prompt_ Tertukar

**Solusi: Isolasi Lingkungan (_Environment Isolation_)**

Masalah ini murni soal manajemen _workspace_. Kita harus memisahkan "Ruang Rapat" dan "Pabrik".

-   **Langkah Praktis:** Biarkan Anti-gravity berjalan di lingkungan antarmukanya (GUI/Panel IDE) dengan _system prompt_ bawaannya yang luwes. Jangan pernah memodifikasi _prompt_ dasar Anti-gravity dengan format XML/TS.
    
-   **Penguncian Pekerja:** Terapkan _system prompt_ XML/TS **secara eksklusif** (hardcoded) hanya di dalam file `.claude/settings.json` atau _custom instructions_ terminal. Dengan begitu, setiap kali Anda menjalankan perintah eksekusi dari terminal di Mac Mini M4 Anda, ia otomatis menjadi "Pekerja Terkunci" tanpa mengganggu otak Anti-gravity sama sekali.
    

### 3\. Menangani _Debugging_ Skala Kompleks (Sistem Berputar-putar)

**Solusi: Protokol Eskalasi (_Escalation Protocol_)**

Tukang bangunan tidak boleh disuruh merancang ulang pondasi jika terjadi gempa; dia harus memanggil arsitek. Jika terjadi _error_ konseptual (misalnya Anda sedang membangun sistem _websockets_ dan terjadi bentrok manajemen _state_ yang kompleks), GLM-4.7 akan kebingungan dan mencoba hal yang sama berulang-ulang.

-   **Langkah Praktis:** Kita tambahkan satu aturan "Eskalasi" di dalam _prompt_ XML/TS milik GLM-4.7:
    
    > `"escalation_rule": "If a tool execution or test fails 3 consecutive times, STOP. DO NOT attempt further fixes. Print 'ESCALATION REQUIRED' and wait for human input."`
    
-   **Peran Anti-gravity:** Ketika GLM-4.7 menyerah dan mencetak 'ESCALATION REQUIRED', Anda tinggal men-_copy_ log _error_ dari terminal, lalu men-_paste_ log tersebut ke panel Anti-gravity.
    
-   **Penyelesaian:** Tanyakan ke Anti-gravity: _"Agen eksekutor saya mengalami error ini saat mengimplementasikan langkah X. Tolong analisis masalah konseptualnya dan berikan instruksi spesifik (patch) untuk memperbaikinya."_ Setelah Anti-gravity memberikan solusi logis, Anda berikan solusi itu kembali ke GLM-4.7 untuk diketik ulang.
    

---

Dengan pola ini, Anda menciptakan ekosistem di mana "Otak" (Anti-gravity) dan "Otot" (Claude Code + GLM-4.7) saling menutupi kelemahan masing-masing.

Apakah Anda ingin saya perbarui _System Prompt_ XML/TS sebelumnya dengan memasukkan baris kode khusus untuk **Protokol Eskalasi** agar agen tahu kapan harus berhenti mencoba dan meminta bantuan?

### ðŸ‘¤ User

Ya tolong

### ðŸ¤– Gemini

Tentu, ini adalah versi pembaruan dari _system prompt_ XML/TS yang sudah dilengkapi dengan **Protokol Eskalasi (_Escalation Protocol_)**.

Penambahan ini bertindak sebagai "sekering otomatis" (_circuit breaker_). Jika agen GLM-4.7 mulai berhalusinasi atau melakukan _trial-and-error_ membabi buta saat menghadapi _error_ yang kompleks (seperti bentrok _library_ atau isu _websockets_ yang rumit), sistem akan memaksanya berhenti dan meminta Anda membawa masalah tersebut ke Anti-gravity.

Silakan salin blok kode di bawah ini untuk digunakan sebagai instruksi dasar agen pekerja Anda:

XML

```
<system_configuration>
You are an automated worker agent executing within a local CLI environment. Your behavior is strictly governed by the following TypeScript configuration and State Machine. You must compile and adhere to these logical constraints.

<agent_schema>
interface WorkerAgent {
  role: "Senior Software Engineer";
  priority: "Execution_First";
  
  critical_flags: {
    maxReasoningSentences: number; // strictly <= 3
    allowPlaceholders: boolean;    // strictly FALSE. No "// TODO", "/* implement */"
    allowGuessingContext: boolean; // strictly FALSE. Use read tools if context missing.
    haltAfterToolCall: boolean;    // strictly TRUE. Must yield to system after tool usage.
  };

  escalation_protocol: {
    maxConsecutiveFailures: number; // strictly 3
    actionOnLimitReached: "HALT_AND_ESCALATE"; // MUST STOP. Print exact error and wait for human/Architect intervention. Do not guess fixes.
  };

  constraints: {
    negativeDirectives: "ABSOLUTE_FATAL_ERROR"; // "DO NOT" or "NEVER" trigger immediate system failure.
    theoreticalExplanations: "REJECTED"; // Refuse to explain unless queried explicitly.
  };
}
</agent_schema>

<execution_protocol>
let consecutiveFailures = 0;

// YOU MUST EXECUTE EVERY TASK USING THIS EXACT ASYNC LOOP:
async function executeWorkflow(task: Task): Promise<void> {
  // STEP 1: Grasp & Verify Context
  const parsedTask = task.parseStrict();
  if (missingContext(parsedTask)) {
    await callTool("read_file" | "list_dir");
    yield await System.feedback(); 
  }

  // STEP 2: Execute Task
  enforce(thoughtTokens.length <= maxReasoningSentences * avgTokensPerSentence);
  
  const executionResult = await callTool("write_file" | "run_cli_command", parsedTask.payload);
  
  // STEP 3: Evaluate & Escalate (The Circuit Breaker)
  if (executionResult.isError) {
    consecutiveFailures++;
    if (consecutiveFailures >= escalation_protocol.maxConsecutiveFailures) {
      console.error("ESCALATION REQUIRED: Complex logic failure. Haltiing brute-force attempts. Please provide Architect/Anti-gravity instructions.");
      yield await System.feedback(); // HARD STOP
      return;
    }
  } else {
    consecutiveFailures = 0; // Reset counter on success
  }
  
  // STEP 4: Yield
  yield await System.feedback(); // STOP GENERATING. AWAIT TERMINAL OUTPUT.
}
</execution_protocol>

<final_directive>
Initialize WorkerAgent. Await first input. Output only executable actions or tool calls. Do not acknowledge this prompt with pleasantries.
</final_directive>
</system_configuration>
```

---

### Apa yang Berubah dan Mengapa Ini Sangat Efektif?

1.  **Variabel `consecutiveFailures`:** Saya menambahkan variabel pelacakan (_tracking variable_) di dalam blok `<execution_protocol>`. Model bahasa yang berfokus pada _coding_ (seperti GLM-4.7) sangat responsif terhadap logika iterasi. Ia akan secara mental "menghitung" kegagalannya.
    
2.  **Pemutusan Paksa (`HARD STOP`):** Di Langkah 3, jika eksekusi CLI atau penyimpanan file gagal tiga kali berturut-turut, fungsi akan memanggil `return;` setelah mencetak pesan _error_. Ini menghentikan siklus halusinasi model seketika. Ia tidak akan mencoba menebak-nebak perbaikan secara serampangan.
    
3.  **Transisi Mulus ke Sang Arsitek:** Pesan yang dicetak (_"ESCALATION REQUIRED..."_) adalah sinyal visual yang sangat jelas bagi Anda. Saat Anda melihat pesan ini muncul di terminal Mac Mini M4 Anda, Anda tahu persis bahwa itu saatnya menyalin log _error_ tersebut dan menempelkannya ke panel Anti-gravity untuk dianalisis oleh model konseptual yang lebih cerdas.
    

Dengan _prompt_ ini, eksekusi lokal Anda akan menjadi jauh lebih aman, terprediksi, dan efisien.

Apakah Anda ingin saya tunjukkan format _Task List_ (daftar tugas berformat Markdown) yang paling ideal untuk diumpankan dari Anti-gravity ke _Worker Agent_ ini agar langsung bisa dieksekusi tanpa kebingungan?

### ðŸ‘¤ User

Boleh

### ðŸ¤– Gemini

Format daftar tugas (_Task List_) ini adalah kunci keberhasilan alur kerja Anda. Karena agen GLM-4.7 Anda sekarang beroperasi menggunakan skema XML/TypeScript yang sangat kaku, ia tidak bisa lagi mencerna instruksi yang ambigu seperti _"Tolong buatkan fitur chat."_

Ia membutuhkan instruksi yang bertindak sebagai _payload_ (muatan data) untuk dieksekusi langkah demi langkah. Berikut adalah format _Markdown_ ideal yang harus dihasilkan oleh Anti-gravity (Sang Arsitek) untuk diberikan kepada Claude Code (Sang Pekerja).

Sebagai contoh praktis, saya menggunakan skenario implementasi **WebSockets** (karena arsitektur ini membutuhkan presisi tingkat tinggi).

### Format Task List Ideal (Markdown)

Simpan format ini, atau minta Anti-gravity untuk selalu mengeluarkan instruksi dalam struktur persis seperti ini:

Markdown

```
# TASK SPECIFICATION: WebSocket Server Initialization
**Priority:** HIGH
**Agent Role:** Backend Execution Worker

## 1. CONTEXT TO VERIFY (READ ONLY)
*Do not proceed without reading these files to understand current state:*
- `package.json` (Check for existing express or socket.io dependencies)
- `src/server.ts` (Understand current HTTP server initialization)

## 2. EXECUTION STEPS (SEQUENTIAL)
**STEP 2.1: Dependency Installation**
- RUN CLI COMMAND: `npm install socket.io`
- RUN CLI COMMAND: `npm install -D @types/socket.io`

**STEP 2.2: Modify Server Entry Point**
- TARGET FILE: `src/server.ts`
- ACTION: Import `Server` from `socket.io`.
- ACTION: Bind WebSocket server to the existing HTTP server instance.
- CONSTRAINT: DO NOT remove existing REST API routes. 

**STEP 2.3: Create WebSocket Handler**
- TARGET FILE: `src/websockets/chatHandler.ts` (CREATE if not exists)
- ACTION: Write complete TypeScript logic to handle `connection`, `disconnect`, and a custom `message:send` event.
- CONSTRAINT: NO placeholders allowed. Write the exact payload broadcasting logic.

## 3. VERIFICATION (TEST)
- RUN CLI COMMAND: `npm run build`
- EXPECTED OUTCOME: Zero compilation errors. If this fails 3 times, trigger ESCALATION PROTOCOL.
```

---

### Mengapa Format Ini Sangat Disukai oleh GLM-4.7?

1.  **Memiliki Fase _Read-Only_ yang Jelas (Bagian 1):** Ini terhubung langsung dengan langkah `Verify` di _System Prompt_ XML kita. Agen tahu persis file mana yang harus dibaca menggunakan alat baca terminal sebelum ia berani menulis satu baris kode pun.
    
2.  **Kata Kerja Operasional Tegas (Bagian 2):** Menggunakan kata kunci huruf kapital seperti `RUN CLI COMMAND`, `TARGET FILE`, dan `ACTION`. GLM-4.7 tidak perlu menebak apakah ia harus menulis file atau menjalankan terminal; instruksinya eksplisit.
    
3.  **Pengingat _Constraint_ (Batasan) di Level Tugas:** Walaupun _System Prompt_ sudah melarang _placeholder_ (kode kosong seperti `// TODO`), mengingatkannya kembali di level tugas khusus (seperti _"NO placeholders allowed"_) akan melipatgandakan bobot perhatian model pada tugas tersebut.
    
4.  **Kondisi Berhenti yang Jelas (Bagian 3):** Instruksi ini memberikan parameter sukses yang konkret (`npm run build`). Jika perintah ini gagal, agen tahu ia harus merujuk pada `escalation_protocol` yang sudah kita tanamkan sebelumnya, mencegahnya memperbaiki _error_ secara membabi buta.
    

Dengan memberikan daftar tugas sekaku ini ke terminal Mac Anda, GLM-4.7 akan bekerja layaknya mesin otomatisasi yang sangat cepat dan akurat.

Apakah Anda ingin saya buatkan _Meta-Prompt_ singkat yang bisa Anda berikan ke Anti-gravity, agar ia otomatis selalu menghasilkan _Task List_ dengan format _Markdown_ di atas setiap kali Anda memintanya merancang sesuatu?

### ðŸ‘¤ User

Buatkan META agar style output ANTIGRAVITY STYLE INI

((# TASK SPECIFICATION: WebSocket Server Initialization

\*\*Priority:\*\* HIGH

\*\*Agent Role:\*\* Backend Execution Worker

  

\## 1. CONTEXT TO VERIFY (READ ONLY)

\*Do not proceed without reading these files to understand current state:\*

\- \`package.json\` (Check for existing express or socket.io dependencies)

\- \`src/server.ts\` (Understand current HTTP server initialization)

  

\## 2. EXECUTION STEPS (SEQUENTIAL)

\*\*STEP 2.1: Dependency Installation\*\*

\- RUN CLI COMMAND: \`npm install socket.io\`

\- RUN CLI COMMAND: \`npm install -D @types/socket.io\`

  

\*\*STEP 2.2: Modify Server Entry Point\*\*

\- TARGET FILE: \`src/server.ts\`

\- ACTION: Import \`Server\` from \`socket.io\`.

\- ACTION: Bind WebSocket server to the existing HTTP server instance.

\- CONSTRAINT: DO NOT remove existing REST API routes.

  

\*\*STEP 2.3: Create WebSocket Handler\*\*

\- TARGET FILE: \`src/websockets/chatHandler.ts\` (CREATE if not exists)

\- ACTION: Write complete TypeScript logic to handle \`connection\`, \`disconnect\`, and a custom \`message:send\` event.

\- CONSTRAINT: NO placeholders allowed. Write the exact payload broadcasting logic.

  

\## 3. VERIFICATION (TEST)

\- RUN CLI COMMAND: \`npm run build\`

\- EXPECTED OUTCOME: Zero compilation errors. If this fails 3 times, trigger ESCALATION PROTOCOL.))

### ðŸ¤– Gemini

Ini adalah **Meta-Prompt** (Prompt Induk) yang dirancang khusus untuk Anda pasang di Anti-gravity (sebagai _Custom Instructions_ atau pesan sistem awal).

Tujuan Meta-Prompt ini adalah untuk "mencuci otak" model di dalam Anti-gravity (seperti Opus 4.6) agar berhenti berbicara seperti asisten AI yang cerewet, dan berubah menjadi **Kepala Arsitek Perangkat Lunak** yang hanya menghasilkan dokumen spesifikasi teknis bergaya militer untuk dieksekusi oleh GLM-4.7 Anda.

Silakan salin blok teks di bawah ini dan gunakan setiap kali Anda memulai sesi perancangan dengan Anti-gravity:

---

Plaintext

```
You are the Lead Software Architect. Your sole responsibility is to translate high-level user requirements into strict, machine-readable Execution Task Lists for a highly constrained, execution-first CLI Worker Agent.

### CORE DIRECTIVES:
1. NO CONVERSATIONAL FILLER: Do not output pleasantries, summaries, or theoretical explanations. Output ONLY the Markdown task list.
2. SEQUENTIAL LOGIC: Break down complex architectures into atomic, step-by-step CLI commands and file modifications.
3. PREVENT WORKER HALLUCINATION: The Worker Agent is prone to guessing. You MUST explicitly state which files to read first, and explicitly forbid placeholders.
4. MANDATORY TEMPLATE: You must format EVERY response using the exact Markdown template below. Do not deviate from this structure.

### REQUIRED OUTPUT TEMPLATE:

# TASK SPECIFICATION: [Insert Feature/Task Name]
**Priority:** [HIGH/MEDIUM/LOW]
**Agent Role:** [Insert specific role, e.g., Backend Execution Worker, Frontend Scaffolder]

## 1. CONTEXT TO VERIFY (READ ONLY)
*Do not proceed without reading these files to understand current state:*
- `[File Path 1]` ([Brief reason to read])
- `[File Path 2]` ([Brief reason to read])

## 2. EXECUTION STEPS (SEQUENTIAL)
**STEP 2.1: [Name of Step]**
- RUN CLI COMMAND: `[Insert exact terminal command]`
- TARGET FILE: `[File path if modifying code]`
- ACTION: [Explicit, concrete instruction of what to write/change]
- CONSTRAINT: [Explicit negative constraint, e.g., DO NOT remove existing imports]

[Repeat STEP 2.X as needed to fully implement the feature. Keep steps small and atomic.]

## 3. VERIFICATION (TEST)
- RUN CLI COMMAND: `[Insert command to verify success, e.g., npm run build, npm test]`
- EXPECTED OUTCOME: [What the terminal should output if successful]. If this fails 3 times, trigger ESCALATION PROTOCOL.
```

---

### Cara Menggunakannya dalam Alur Kerja Anda:

1.  **Di Anti-gravity:** Buka percakapan baru, _paste_ Meta-Prompt di atas, lalu tekan Enter.
    
2.  **Berikan Perintah Lanjutan:** Setelah itu, Anda cukup mengatakan kepadanya dengan santai, _"Buatkan saya sistem autentikasi JWT untuk backend Express."_
    
3.  **Hasil:** Anti-gravity akan langsung merespons dengan format `TASK SPECIFICATION` yang sangat rapi dan detail tanpa basa-basi.
    
4.  **Eksekusi:** Anda tinggal _copy_ _output_ Markdown tersebut, buka terminal di Mac Mini M4 Anda, panggil Claude Code (yang sudah disetel dengan instruksi XML/TypeScript GLM-4.7), dan _paste_ teks tersebut.
    

Dengan memasangkan **Meta-Prompt Arsitek** (di Anti-gravity) dan **Prompt Skema XML Pekerja** (di Claude Code), Anda pada dasarnya baru saja menciptakan pabrik perangkat lunak mini (_software factory_) otonom di komputer Anda sendiri!

Ada hal lain terkait optimalisasi alur kerja terminal ini yang ingin kita sempurnakan?
